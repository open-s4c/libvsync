/*
 * Copyright (C) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 * SPDX-License-Identifier: MIT
 */

#ifndef VATOMIC_CONFIG_U8_RLX_H
#define VATOMIC_CONFIG_U8_RLX_H
/* !!!Warning: File generated by tmpl; DO NOT EDIT.!!! */

#include <vsync/atomic/await.h>

#if defined(VATOMIC_ENABLE_ATOMIC_RLX)

    #define VATOMIC8_READ
static inline vuint8_t
vatomic8_read(const vatomic8_t *a)
{
    return vatomic8_read_rlx(a);
}
    #define VATOMIC8_READ_ACQ
static inline vuint8_t
vatomic8_read_acq(const vatomic8_t *a)
{
    return vatomic8_read_rlx(a);
}

    #define VATOMIC8_WRITE
static inline void
vatomic8_write(vatomic8_t *a, vuint8_t v)
{
    vatomic8_write_rlx(a, v);
}
    #define VATOMIC8_WRITE_REL
static inline void
vatomic8_write_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_write_rlx(a, v);
}

    #define VATOMIC8_XCHG
static inline vuint8_t
vatomic8_xchg(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_xchg_rlx(a, v);
}
    #define VATOMIC8_XCHG_ACQ
static inline vuint8_t
vatomic8_xchg_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_xchg_rlx(a, v);
}
    #define VATOMIC8_XCHG_REL
static inline vuint8_t
vatomic8_xchg_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_xchg_rlx(a, v);
}

    #define VATOMIC8_CMPXCHG
static inline vuint8_t
vatomic8_cmpxchg(vatomic8_t *a, vuint8_t e, vuint8_t v)
{
    return vatomic8_cmpxchg_rlx(a, e, v);
}
    #define VATOMIC8_CMPXCHG_ACQ
static inline vuint8_t
vatomic8_cmpxchg_acq(vatomic8_t *a, vuint8_t e, vuint8_t v)
{
    return vatomic8_cmpxchg_rlx(a, e, v);
}
    #define VATOMIC8_CMPXCHG_REL
static inline vuint8_t
vatomic8_cmpxchg_rel(vatomic8_t *a, vuint8_t e, vuint8_t v)
{
    return vatomic8_cmpxchg_rlx(a, e, v);
}

    #define VATOMIC8_GET_MAX
static inline vuint8_t
vatomic8_get_max(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_max_rlx(a, v);
}
    #define VATOMIC8_GET_AND
static inline vuint8_t
vatomic8_get_and(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_and_rlx(a, v);
}
    #define VATOMIC8_GET_OR
static inline vuint8_t
vatomic8_get_or(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_or_rlx(a, v);
}
    #define VATOMIC8_GET_XOR
static inline vuint8_t
vatomic8_get_xor(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_xor_rlx(a, v);
}
    #define VATOMIC8_GET_ADD
static inline vuint8_t
vatomic8_get_add(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_add_rlx(a, v);
}
    #define VATOMIC8_GET_SUB
static inline vuint8_t
vatomic8_get_sub(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_sub_rlx(a, v);
}
    #define VATOMIC8_MAX_GET
static inline vuint8_t
vatomic8_max_get(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_max_get_rlx(a, v);
}
    #define VATOMIC8_AND_GET
static inline vuint8_t
vatomic8_and_get(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_and_get_rlx(a, v);
}
    #define VATOMIC8_OR_GET
static inline vuint8_t
vatomic8_or_get(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_or_get_rlx(a, v);
}
    #define VATOMIC8_XOR_GET
static inline vuint8_t
vatomic8_xor_get(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_xor_get_rlx(a, v);
}
    #define VATOMIC8_ADD_GET
static inline vuint8_t
vatomic8_add_get(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_add_get_rlx(a, v);
}
    #define VATOMIC8_SUB_GET
static inline vuint8_t
vatomic8_sub_get(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_sub_get_rlx(a, v);
}
    #define VATOMIC8_GET_MAX_ACQ
static inline vuint8_t
vatomic8_get_max_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_max_rlx(a, v);
}
    #define VATOMIC8_GET_AND_ACQ
static inline vuint8_t
vatomic8_get_and_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_and_rlx(a, v);
}
    #define VATOMIC8_GET_OR_ACQ
static inline vuint8_t
vatomic8_get_or_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_or_rlx(a, v);
}
    #define VATOMIC8_GET_XOR_ACQ
static inline vuint8_t
vatomic8_get_xor_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_xor_rlx(a, v);
}
    #define VATOMIC8_GET_ADD_ACQ
static inline vuint8_t
vatomic8_get_add_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_add_rlx(a, v);
}
    #define VATOMIC8_GET_SUB_ACQ
static inline vuint8_t
vatomic8_get_sub_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_sub_rlx(a, v);
}
    #define VATOMIC8_MAX_GET_ACQ
static inline vuint8_t
vatomic8_max_get_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_max_get_rlx(a, v);
}
    #define VATOMIC8_AND_GET_ACQ
static inline vuint8_t
vatomic8_and_get_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_and_get_rlx(a, v);
}
    #define VATOMIC8_OR_GET_ACQ
static inline vuint8_t
vatomic8_or_get_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_or_get_rlx(a, v);
}
    #define VATOMIC8_XOR_GET_ACQ
static inline vuint8_t
vatomic8_xor_get_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_xor_get_rlx(a, v);
}
    #define VATOMIC8_ADD_GET_ACQ
static inline vuint8_t
vatomic8_add_get_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_add_get_rlx(a, v);
}
    #define VATOMIC8_SUB_GET_ACQ
static inline vuint8_t
vatomic8_sub_get_acq(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_sub_get_rlx(a, v);
}
    #define VATOMIC8_GET_MAX_REL
static inline vuint8_t
vatomic8_get_max_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_max_rlx(a, v);
}
    #define VATOMIC8_GET_AND_REL
static inline vuint8_t
vatomic8_get_and_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_and_rlx(a, v);
}
    #define VATOMIC8_GET_OR_REL
static inline vuint8_t
vatomic8_get_or_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_or_rlx(a, v);
}
    #define VATOMIC8_GET_XOR_REL
static inline vuint8_t
vatomic8_get_xor_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_xor_rlx(a, v);
}
    #define VATOMIC8_GET_ADD_REL
static inline vuint8_t
vatomic8_get_add_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_add_rlx(a, v);
}
    #define VATOMIC8_GET_SUB_REL
static inline vuint8_t
vatomic8_get_sub_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_get_sub_rlx(a, v);
}
    #define VATOMIC8_MAX_GET_REL
static inline vuint8_t
vatomic8_max_get_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_max_get_rlx(a, v);
}
    #define VATOMIC8_AND_GET_REL
static inline vuint8_t
vatomic8_and_get_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_and_get_rlx(a, v);
}
    #define VATOMIC8_OR_GET_REL
static inline vuint8_t
vatomic8_or_get_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_or_get_rlx(a, v);
}
    #define VATOMIC8_XOR_GET_REL
static inline vuint8_t
vatomic8_xor_get_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_xor_get_rlx(a, v);
}
    #define VATOMIC8_ADD_GET_REL
static inline vuint8_t
vatomic8_add_get_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_add_get_rlx(a, v);
}
    #define VATOMIC8_SUB_GET_REL
static inline vuint8_t
vatomic8_sub_get_rel(vatomic8_t *a, vuint8_t v)
{
    return vatomic8_sub_get_rlx(a, v);
}

    #define VATOMIC8_GET_INC
static inline vuint8_t
vatomic8_get_inc(vatomic8_t *a)
{
    return vatomic8_get_inc_rlx(a);
}
    #define VATOMIC8_INC_GET
static inline vuint8_t
vatomic8_inc_get(vatomic8_t *a)
{
    return vatomic8_inc_get_rlx(a);
}
    #define VATOMIC8_GET_DEC
static inline vuint8_t
vatomic8_get_dec(vatomic8_t *a)
{
    return vatomic8_get_dec_rlx(a);
}
    #define VATOMIC8_DEC_GET
static inline vuint8_t
vatomic8_dec_get(vatomic8_t *a)
{
    return vatomic8_dec_get_rlx(a);
}
    #define VATOMIC8_GET_INC_ACQ
static inline vuint8_t
vatomic8_get_inc_acq(vatomic8_t *a)
{
    return vatomic8_get_inc_rlx(a);
}
    #define VATOMIC8_INC_GET_ACQ
static inline vuint8_t
vatomic8_inc_get_acq(vatomic8_t *a)
{
    return vatomic8_inc_get_rlx(a);
}
    #define VATOMIC8_GET_DEC_ACQ
static inline vuint8_t
vatomic8_get_dec_acq(vatomic8_t *a)
{
    return vatomic8_get_dec_rlx(a);
}
    #define VATOMIC8_DEC_GET_ACQ
static inline vuint8_t
vatomic8_dec_get_acq(vatomic8_t *a)
{
    return vatomic8_dec_get_rlx(a);
}
    #define VATOMIC8_GET_INC_REL
static inline vuint8_t
vatomic8_get_inc_rel(vatomic8_t *a)
{
    return vatomic8_get_inc_rlx(a);
}
    #define VATOMIC8_INC_GET_REL
static inline vuint8_t
vatomic8_inc_get_rel(vatomic8_t *a)
{
    return vatomic8_inc_get_rlx(a);
}
    #define VATOMIC8_GET_DEC_REL
static inline vuint8_t
vatomic8_get_dec_rel(vatomic8_t *a)
{
    return vatomic8_get_dec_rlx(a);
}
    #define VATOMIC8_DEC_GET_REL
static inline vuint8_t
vatomic8_dec_get_rel(vatomic8_t *a)
{
    return vatomic8_dec_get_rlx(a);
}

    #define VATOMIC8_MAX
static inline void
vatomic8_max(vatomic8_t *a, vuint8_t v)
{
    vatomic8_max_rlx(a, v);
}
    #define VATOMIC8_AND
static inline void
vatomic8_and(vatomic8_t *a, vuint8_t v)
{
    vatomic8_and_rlx(a, v);
}
    #define VATOMIC8_OR
static inline void
vatomic8_or(vatomic8_t *a, vuint8_t v)
{
    vatomic8_or_rlx(a, v);
}
    #define VATOMIC8_XOR
static inline void
vatomic8_xor(vatomic8_t *a, vuint8_t v)
{
    vatomic8_xor_rlx(a, v);
}
    #define VATOMIC8_ADD
static inline void
vatomic8_add(vatomic8_t *a, vuint8_t v)
{
    vatomic8_add_rlx(a, v);
}
    #define VATOMIC8_SUB
static inline void
vatomic8_sub(vatomic8_t *a, vuint8_t v)
{
    vatomic8_sub_rlx(a, v);
}
    #define VATOMIC8_MAX_REL
static inline void
vatomic8_max_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_max_rlx(a, v);
}
    #define VATOMIC8_AND_REL
static inline void
vatomic8_and_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_and_rlx(a, v);
}
    #define VATOMIC8_OR_REL
static inline void
vatomic8_or_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_or_rlx(a, v);
}
    #define VATOMIC8_XOR_REL
static inline void
vatomic8_xor_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_xor_rlx(a, v);
}
    #define VATOMIC8_ADD_REL
static inline void
vatomic8_add_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_add_rlx(a, v);
}
    #define VATOMIC8_SUB_REL
static inline void
vatomic8_sub_rel(vatomic8_t *a, vuint8_t v)
{
    vatomic8_sub_rlx(a, v);
}

    #define VATOMIC8_INC
static inline void
vatomic8_inc(vatomic8_t *a)
{
    vatomic8_inc_rlx(a);
}
    #define VATOMIC8_DEC
static inline void
vatomic8_dec(vatomic8_t *a)
{
    vatomic8_dec_rlx(a);
}
    #define VATOMIC8_INC_REL
static inline void
vatomic8_inc_rel(vatomic8_t *a)
{
    vatomic8_inc_rlx(a);
}
    #define VATOMIC8_DEC_REL
static inline void
vatomic8_dec_rel(vatomic8_t *a)
{
    vatomic8_dec_rlx(a);
}

#endif
#endif
